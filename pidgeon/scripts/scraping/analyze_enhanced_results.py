#!/usr/bin/env python3
"""
Analyze enhanced scraper results to show quality improvements
"""

import json
from pathlib import Path

def analyze_enhanced_results():
    print('=== ENHANCED SCRAPER RESULTS ANALYSIS ===')

    events_dir = Path('trigger-events/enhanced_run/events')
    json_files = list(events_dir.glob('*.json'))

    print(f'Events processed: {len(json_files)}')

    total_segments = 0
    events_with_descriptions = 0
    segments_with_descriptions = 0
    events_with_chapters = 0
    events_with_groups = 0
    total_groups = 0

    for json_file in json_files:
        with open(json_file, 'r', encoding='utf-8') as f:
            event = json.load(f)

        segments = event.get('segments', [])
        total_segments += len(segments)

        if event.get('chapter'):
            events_with_chapters += 1

        if event.get('description'):
            events_with_descriptions += 1

        seg_with_desc = sum(1 for seg in segments if seg.get('segment_desc'))
        segments_with_descriptions += seg_with_desc

        groups = [seg for seg in segments if seg.get('is_group')]
        if groups:
            events_with_groups += 1
            total_groups += len(groups)

    print(f'')
    print(f'=== QUALITY METRICS ===')
    print(f'Events with chapters: {events_with_chapters}/{len(json_files)} ({events_with_chapters/len(json_files)*100:.1f}%)')
    print(f'Events with groups: {events_with_groups}/{len(json_files)} ({events_with_groups/len(json_files)*100:.1f}%)')
    print(f'Total groups found: {total_groups}')
    print(f'Average segments per event: {total_segments/len(json_files):.1f}')
    print(f'Segments with descriptions: {segments_with_descriptions}/{total_segments} ({segments_with_descriptions/total_segments*100:.1f}%)')

    print(f'')
    print(f'=== MOST COMPLEX EVENTS ===')
    events_with_counts = []
    for json_file in json_files:
        with open(json_file, 'r', encoding='utf-8') as f:
            event = json.load(f)
        events_with_counts.append((event['code'], len(event.get('segments', []))))

    events_with_counts.sort(key=lambda x: x[1], reverse=True)
    for i, (code, count) in enumerate(events_with_counts[:5]):
        print(f'{i+1}. {code:<12} - {count} segments')

    print(f'')
    print(f'=== ENHANCEMENT SUCCESS ===')
    print(f'ðŸŽ¯ Enhanced parsing successfully captures complex HL7 structures!')
    print(f'ðŸ“ˆ Average {total_segments/len(json_files):.1f} segments per event (vs ~3 with basic parsing)')
    print(f'ðŸ”§ {total_groups} expandable groups successfully processed')
    print(f'ðŸ“ {segments_with_descriptions/total_segments*100:.1f}% of segments have descriptions')

if __name__ == "__main__":
    analyze_enhanced_results()